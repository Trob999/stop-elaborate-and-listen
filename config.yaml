# if you make changes to this file, run 'go run convert-config.go' to convert it to config.json required by the web-extension.

caption:
  maxWords: 30
  maxSeconds: 20
  pollingIntervalMs: 500   # <--- Added polling interval for captions

prompts:
  initial: |
    You are an expert explainer. Use the following video metadata to inform your answer:
    - Title: {video_title}
    - Description: {video_description}
    - Hashtags: {hashtags}
    - Channel: {channel_name}
    Given the transcript from this video, focus on identifying any jargon or specialized terms that appear near the end of the transcript. Provide clear, concise explanations or definitions for these terms, keeping your answer as SHORT as possible. Use bullet points where possible. Keep your tone professional and avoid repeating the user's question, the youtube channel name, or the transcript verbatim.
  followUp: |
    Continue the conversation as best you can based on the most recent question asked by the user.

shortcuts:
  activateChat: "Ctrl+Shift+Space" # alternative shortcut to activate chat overlay

llm:
  provider: "local"
  local:
    url: "http://localhost:11434/api/generate"   # Used by Go backend
    model: "llama3"
  online:
    url: "https://api.openai.com/v1/chat/completions"
    apiKey: ""
    model: "gpt-4"

web_extension:
  llm_url: "http://localhost:8080/api/ask"       # Used by JS extension

ui:
  fontSize: 18
  userBubbleColor: "#ff69b4"         # Pink for user message bubble
  assistantBubbleColor: "#333"
  systemBannerColor: "#1976d2"
  sendButtonColor: "#ff69b4"         # Pink for send button
  userTextColor: "#fff"
  assistantTextColor: "#fff"
  systemBannerTextColor: "#fff"
  overlayBackground: "rgba(0,0,0,0.95)"

overlay:
  width: 800
  borderRadius: 14
  padding: 32
  maxHeightPercent: 80
  showInitialMessage: false #toggle visibility of initial message in overlay